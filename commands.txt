import java.io.{BufferedWriter, OutputStreamWriter}
import java.util.concurrent.atomic.AtomicInteger
import org.apache.spark.{HashPartitioner, Partitioner, SparkConf, SparkContext}
import org.apache.spark.SparkContext._
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.SQLContext
import org.apache.hadoop.conf.Configuration
import org.apache.hadoop.fs._
import org.apache.hadoop.mapred.lib.MultipleTextOutputFormat
import org.apache.hadoop.io.NullWritable
import org.apache.hadoop.util.Progressable

class MyPartitioner(partitions: Int) extends Partitioner {
  override def numPartitions: Int = partitions

  override def getPartition(key: Any): Int = {
    (key.toString.hashCode & Integer.MAX_VALUE) % numPartitions // make sure lines with the same key in the same partition
  }
}

val files = sc.wholeTextFiles("file:///home/cloudera/Downloads/data/small/*_[a-c].txt")

//    val partitionedFiles = sc.textFile("file:///home/cloudera/Downloads/simplesparkapp-master/data/task/")
  //  partitionedFiles.foreachPartition(lines => {
    //  lines.mkString
   // })

    val modifiedFiles = files.map({ case (filename, content) => {
      val split: String = filename.split("_")(0)
      val i: Int = split.lastIndexOf("/") + 1
      (split.substring(i), content)
    } })

    val groupedByFileName = modifiedFiles.groupBy(_._1)

    val map = groupedByFileName.map({ case (fn, content) => (fn, content.map(_._2).mkString) })

    val destinationFile = "output.txt"

    val file = "output.txt"

    val partitionedMap = map.partitionBy(new MyPartitioner(10))

    def writeLines(iterator: Iterator[(String, String)]) = {
          val outs = new collection.mutable.ArrayBuffer[FSDataOutputStream]()
          for ((key, line) <- iterator) {

              val path: String = s"/test2/$key.txt"
              val path1: Path = new Path(path)
              val conf: Configuration = new Configuration()
              conf.addResource("/etc/hadoop/conf/core-site.xml")
              conf.addResource("/etc/hadoop/conf/hdfs-site.xml")

              val outputStream: FSDataOutputStream = FileSystem.get(conf).create(path1, false)

              outputStream.writeChars(line)
            outputStream.close()
            }
        }

partitionedMap.foreachPartition(writeLines)
